{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")  # Add the parent directory to the path\n",
    "\n",
    "import os \n",
    "import torch \n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "from gsplat.rendering import rasterization\n",
    "import yaml\n",
    "from gsplat.strategy.default import DefaultStrategy\n",
    "from munch import munchify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckpt(ckpt_path : str, device=\"cuda\"):\n",
    "    assert os.path.isfile(ckpt_path), f\"checkpoint not found in {ckpt_path}\"\n",
    "    ckpt = torch.load(ckpt_path, map_location=device, weights_only=True)\n",
    "    return ckpt\n",
    "\n",
    "def read_splats(ckpt):\n",
    "    \"\"\" function to read the splats from a pre-trained checkpoint\n",
    "        input  : pytorch checkpooint\n",
    "        output : dictionary of splats \"\"\"\n",
    "    splats = {key : ckpt['splats'][key] for key in ckpt['splats'].keys()}\n",
    "    return splats \n",
    "\n",
    "# Define a constructor function for the DefaultStrategy\n",
    "def default_strategy_constructor(loader, node):\n",
    "    # Here, you can extract any necessary data from the node\n",
    "    # and use it to initialize the DefaultStrategy object.\n",
    "    # For simplicity, we'll assume no additional data is needed.\n",
    "    return DefaultStrategy()\n",
    "\n",
    "# Register the constructor with PyYAML\n",
    "yaml.add_constructor('tag:yaml.org,2002:python/object:gsplat.strategy.default.DefaultStrategy', default_strategy_constructor)\n",
    "\n",
    "def read_config(config_path):\n",
    "    assert os.path.isfile(config_path), f\"configuration did not found in {config_path}\"\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.load(file, Loader=yaml.FullLoader)  # Use yaml.FullLoader to handle Python-specific tags\n",
    "    return config\n",
    "\n",
    "ckpt = load_ckpt(\"/home/sergio/onboarding_stage/gaussian_splatting/results/hope/obj_000001/ckpts/ckpt_14999_rank0.pt\")\n",
    "splats = read_splats(ckpt)\n",
    "points_obj = np.asarray(splats['means'].cpu())\n",
    "config = read_config(\"/home/sergio/onboarding_stage/gaussian_splatting/results/hope/obj_000001/cfg.yml\")\n",
    "cfg = munchify(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute cameras along icosphere "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of camera poses: 42\n"
     ]
    }
   ],
   "source": [
    "def load_point_cloud(file_path):\n",
    "    \"\"\"\n",
    "    Dummy point-cloud loading function.\n",
    "    Replace with your own code to load real data (e.g. .ply or .xyz).\n",
    "    Returns:\n",
    "        points: (N, 3) numpy array\n",
    "    \"\"\"\n",
    "    # For illustration, we generate random points in a box\n",
    "    # Remove or replace this with your real data loading\n",
    "    points = np.random.rand(1000, 3) * 2.0 - 1.0  # random points in [-1, 1]^3\n",
    "    return points\n",
    "\n",
    "def compute_centroid_and_radius(points):\n",
    "    \"\"\"\n",
    "    Compute the centroid (mean of all points) and a radius\n",
    "    proportional to the object size. \n",
    "    \n",
    "    Options for the radius:\n",
    "    1) Half of the maximum bounding-box extent (simple bounding sphere).\n",
    "    2) An actual minimal bounding sphere (more involved).\n",
    "    Here we do the bounding box approach for simplicity.\n",
    "    \"\"\"\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    \n",
    "    # bounding box extents\n",
    "    min_xyz = np.min(points, axis=0)\n",
    "    max_xyz = np.max(points, axis=0)\n",
    "    bbox_size = max_xyz - min_xyz\n",
    "    radius = 0.5 * np.linalg.norm(bbox_size)  # half-diagonal\n",
    "    \n",
    "    return centroid, radius\n",
    "\n",
    "def icosahedron_vertices():\n",
    "    \"\"\"\n",
    "    Return the base icosahedron vertices (12) and faces (20).\n",
    "    The returned vertices are on the unit sphere.\n",
    "    \"\"\"\n",
    "    phi = (1.0 + np.sqrt(5.0)) / 2.0  # golden ratio\n",
    "    # Twelve vertices of an icosahedron\n",
    "    verts = np.array([\n",
    "        [-1,  phi,  0],\n",
    "        [ 1,  phi,  0],\n",
    "        [-1, -phi,  0],\n",
    "        [ 1, -phi,  0],\n",
    "        [ 0, -1,  phi],\n",
    "        [ 0,  1,  phi],\n",
    "        [ 0, -1, -phi],\n",
    "        [ 0,  1, -phi],\n",
    "        [ phi,  0, -1],\n",
    "        [ phi,  0,  1],\n",
    "        [-phi,  0, -1],\n",
    "        [-phi,  0,  1]\n",
    "    ], dtype=np.float64)\n",
    "    \n",
    "    # Normalize to unit sphere\n",
    "    verts /= np.linalg.norm(verts, axis=1)[:, None]\n",
    "    \n",
    "    # Faces of the icosahedron (20 triangular faces)\n",
    "    faces = np.array([\n",
    "        [0, 11, 5], [0, 5, 1], [0, 1, 7], [0, 7, 10], [0, 10, 11],\n",
    "        [1, 5, 9], [5, 11, 4], [11, 10, 2], [10, 7, 6], [7, 1, 8],\n",
    "        [3, 9, 4], [3, 4, 2], [3, 2, 6], [3, 6, 8], [3, 8, 9],\n",
    "        [4, 9, 5], [2, 4, 11], [6, 2, 10], [8, 6, 7], [9, 8, 1]\n",
    "    ], dtype=np.int32)\n",
    "    \n",
    "    return verts, faces\n",
    "\n",
    "def subdivide_icosahedron_once(verts, faces):\n",
    "    \"\"\"\n",
    "    Subdivide each triangle in the icosahedron once.\n",
    "    This yields 42 unique vertices on the unit sphere.\n",
    "    \"\"\"\n",
    "    edge_map = {}\n",
    "    new_faces = []\n",
    "    next_vertex_index = len(verts)\n",
    "    # We’ll store new vertices in a list to append them as we generate them\n",
    "    new_verts = verts.tolist()\n",
    "    \n",
    "    def get_midpoint_index(i1, i2):\n",
    "        \"\"\"\n",
    "        For the edge (i1, i2), compute the midpoint on the unit sphere.\n",
    "        Use a dictionary to avoid duplicating edges.\n",
    "        \"\"\"\n",
    "        # Ensure smaller index first for consistent edge key\n",
    "        if i2 < i1:\n",
    "            i1, i2 = i2, i1\n",
    "        edge_key = (i1, i2)\n",
    "        if edge_key in edge_map:\n",
    "            return edge_map[edge_key]\n",
    "        \n",
    "        # Compute midpoint and normalize\n",
    "        v1 = np.array(new_verts[i1])\n",
    "        v2 = np.array(new_verts[i2])\n",
    "        midpoint = 0.5 * (v1 + v2)\n",
    "        midpoint /= np.linalg.norm(midpoint)\n",
    "        \n",
    "        # Add to new_verts list\n",
    "        new_verts.append(midpoint.tolist())\n",
    "        edge_map[edge_key] = len(new_verts) - 1\n",
    "        return edge_map[edge_key]\n",
    "    \n",
    "    # Subdivide each face\n",
    "    for tri in faces:\n",
    "        iA, iB, iC = tri[0], tri[1], tri[2]\n",
    "        iAB = get_midpoint_index(iA, iB)\n",
    "        iBC = get_midpoint_index(iB, iC)\n",
    "        iCA = get_midpoint_index(iC, iA)\n",
    "        \n",
    "        # Create new faces\n",
    "        new_faces.append([iA, iAB, iCA])\n",
    "        new_faces.append([iB, iBC, iAB])\n",
    "        new_faces.append([iC, iCA, iBC])\n",
    "        new_faces.append([iAB, iBC, iCA])\n",
    "    \n",
    "    new_verts = np.array(new_verts, dtype=np.float64)\n",
    "    new_faces = np.array(new_faces, dtype=np.int32)\n",
    "    \n",
    "    return new_verts, new_faces\n",
    "\n",
    "def generate_icosphere_level_1():\n",
    "    \"\"\"\n",
    "    Generates an icosphere at subdivision level 1.\n",
    "    This should have 42 vertices on the unit sphere.\n",
    "    \"\"\"\n",
    "    base_verts, base_faces = icosahedron_vertices()\n",
    "    verts, faces = subdivide_icosahedron_once(base_verts, base_faces)\n",
    "    # Optionally, you can remove duplicates if needed, but with the edge_map approach,\n",
    "    # we should already have unique vertices.\n",
    "    return verts, faces\n",
    "\n",
    "def look_at(camera_pos, target, up=np.array([0, 1, 0], dtype=float)):\n",
    "    \"\"\"\n",
    "    Compute a standard right-handed look-at camera extrinsic matrix:\n",
    "    \n",
    "    - camera_pos: 3D position of the camera.\n",
    "    - target: 3D position to look at.\n",
    "    - up: approximate \"world up\" vector.\n",
    "    \n",
    "    Returns:\n",
    "        A 4x4 extrinsic matrix (world->camera).\n",
    "        The camera looks down the -Z axis in its local coordinate system.\n",
    "    \"\"\"\n",
    "    forward = camera_pos - target\n",
    "    forward /= np.linalg.norm(forward)  # The -Z axis in camera coords\n",
    "    \n",
    "    # Recompute orthonormal basis\n",
    "    right = np.cross(up, forward)\n",
    "    right /= (np.linalg.norm(right) + 3e-10)\n",
    "    \n",
    "    up_new = np.cross(forward, right)\n",
    "    up_new /= (np.linalg.norm(up_new) + 3e-10)\n",
    "    \n",
    "    # Rotation part\n",
    "    R = np.eye(4, dtype=float)\n",
    "    # Camera’s X axis = 'right'\n",
    "    R[0, 0:3] = right\n",
    "    # Camera’s Y axis = 'up'\n",
    "    R[1, 0:3] = up_new\n",
    "    # Camera’s Z axis = 'forward' (which is -Z from camera’s perspective)\n",
    "    R[2, 0:3] = forward\n",
    "    \n",
    "    # Translation part\n",
    "    T = np.eye(4, dtype=float)\n",
    "    T[0:3, 3] = -camera_pos\n",
    "    \n",
    "    # The extrinsic matrix is R * T\n",
    "    extrinsic = R @ T\n",
    "    \n",
    "    return extrinsic\n",
    "\n",
    "    \n",
    "# 2) Compute centroid and radius\n",
    "centroid, radius = compute_centroid_and_radius(points_obj)\n",
    "    \n",
    "# 3) Generate the icosphere of 42 vertices\n",
    "icosphere_verts, _ = generate_icosphere_level_1()\n",
    "    \n",
    "# 4) Scale and translate icosphere to the centroid with the chosen radius\n",
    "#    Each vertex becomes a camera position\n",
    "camera_positions = icosphere_verts * radius + centroid\n",
    "    \n",
    "# 5) For each camera position, compute the extrinsic matrix looking at the centroid\n",
    "camera_poses = []\n",
    "for cam_pos in camera_positions:\n",
    "    pose = look_at(cam_pos, centroid)\n",
    "    camera_poses.append(pose)\n",
    "    \n",
    "# Print (or store) the results\n",
    "print(f\"Number of camera poses: {len(camera_poses)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 1\n",
    "def rasterize_splats(cfg,\n",
    "    splats : dict,\n",
    "    camtoworlds: Tensor,\n",
    "    Ks: Tensor,\n",
    "    width: int,\n",
    "    height: int,\n",
    "    masks: Optional[Tensor] = None,\n",
    "    **kwargs,\n",
    ") -> Tuple[Tensor, Tensor, Dict]:\n",
    "    means = splats[\"means\"]  # [N, 3]\n",
    "        # quats = F.normalize(self.splats[\"quats\"], dim=-1)  # [N, 4]\n",
    "        # rasterization does normalization internally\n",
    "    quats = splats[\"quats\"]  # [N, 4]\n",
    "    scales = torch.exp(splats[\"scales\"])  # [N, 3]\n",
    "    opacities = torch.sigmoid(splats[\"opacities\"])  # [N,]\n",
    "\n",
    "    # image_ids = kwargs.pop(\"image_ids\", None)\n",
    "    colors = torch.cat([splats[\"sh0\"], splats[\"shN\"]], 1)  # [N, K, 3]\n",
    "\n",
    "    rasterize_mode = \"antialiased\" if cfg.antialiased else \"classic\"\n",
    "    render_colors, render_alphas, info = rasterization(\n",
    "        means=means,\n",
    "        quats=quats,\n",
    "        scales=scales,\n",
    "        opacities=opacities,\n",
    "        colors=colors,\n",
    "        viewmats=torch.linalg.inv(camtoworlds),  # [C, 4, 4]\n",
    "        Ks=Ks,  # [C, 3, 3]\n",
    "        width=width,\n",
    "        height=height,\n",
    "        packed=cfg.packed,\n",
    "        absgrad=(\n",
    "            cfg.strategy.absgrad\n",
    "            if isinstance(cfg.strategy, DefaultStrategy)\n",
    "            else False\n",
    "        ),\n",
    "        sparse_grad=cfg.sparse_grad,\n",
    "        rasterize_mode=rasterize_mode,\n",
    "        distributed=world_size > 1,\n",
    "        camera_model=cfg.camera_model,\n",
    "        **kwargs,\n",
    "    )\n",
    "    if masks is not None:\n",
    "        render_colors[~masks] = 0\n",
    "    return render_colors, render_alphas, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_pose = camera_poses[0]\n",
    "renders, alphas, info = rasterize_splats(\n",
    "    camtoworlds=camt,\n",
    "    Ks=Ks,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    sh_degree=sh_degree_to_use,\n",
    "    near_plane=cfg.near_plane,\n",
    "                far_plane=cfg.far_plane,\n",
    "                image_ids=image_ids,\n",
    "                render_mode=\"RGB+ED\" if cfg.depth_loss else \"RGB\",\n",
    "                masks=masks,\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gs_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
