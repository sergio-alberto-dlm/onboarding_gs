{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")  # Add the parent directory to the path\n",
    "\n",
    "import os \n",
    "import numpy as np \n",
    "import open3d as o3d \n",
    "from utils.colmap_loader import read_pose_matrices\n",
    "from plyfile import PlyData, PlyElement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize point cloud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"hope\"\n",
    "object_id = 1\n",
    "n_views = 7\n",
    "path_pcd_up = f\"/home/sergio/onboarding_stage/data/{dataset}/obj_{object_id:06d}/up/{n_views}_views/sparse/0/points3D.ply\"\n",
    "path_pcd_down = f\"/home/sergio/onboarding_stage/data/{dataset}/obj_{object_id:06d}/down/{n_views}_views/sparse/0/points3D.ply\"\n",
    "point_cloud_up = o3d.io.read_point_cloud(path_pcd_up)\n",
    "point_cloud_down = o3d.io.read_point_cloud(path_pcd_down)\n",
    "\n",
    "pcd_aux_up = o3d.geometry.PointCloud()\n",
    "pcd_aux_up.points = o3d.utility.Vector3dVector(np.asarray(point_cloud_up.points))\n",
    "pcd_aux_up.colors = o3d.utility.Vector3dVector(np.asarray(point_cloud_up.colors))\n",
    "\n",
    "pcd_aux_down = o3d.geometry.PointCloud()\n",
    "pcd_aux_down.points = o3d.utility.Vector3dVector(np.asarray(point_cloud_down.points))\n",
    "pcd_aux_down.colors = o3d.utility.Vector3dVector(np.asarray(point_cloud_down.colors))\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_aux_up, pcd_aux_down])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize point cloud aligned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"hope\"\n",
    "object_id = 1\n",
    "path_pcd_align = f\"/home/sergio/onboarding_stage/data/{dataset}/obj_{object_id:06d}/align/sparse/0/points3D.ply\"\n",
    "pcd_align = o3d.io.read_point_cloud(path_pcd_align)\n",
    "\n",
    "pcd_aux_align = o3d.geometry.PointCloud()\n",
    "pcd_aux_align.points = o3d.utility.Vector3dVector(np.asarray(pcd_align.points))\n",
    "pcd_aux_align.colors = o3d.utility.Vector3dVector(np.asarray(pcd_align.colors))\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_aux_align])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test poses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"hope\"\n",
    "object_id = 1\n",
    "path_pcd = f\"/home/sergio/onboarding_stage/data/{dataset}/obj_{object_id:06d}/align/sparse/0/points3D.ply\"\n",
    "point_cloud = o3d.io.read_point_cloud(path_pcd)\n",
    "\n",
    "pcd_aux = o3d.geometry.PointCloud()\n",
    "pcd_aux.points = o3d.utility.Vector3dVector(np.asarray(point_cloud.points))\n",
    "pcd_aux.colors = o3d.utility.Vector3dVector(np.asarray(point_cloud.colors))\n",
    "center_pcd = pcd_aux.get_center()\n",
    "\n",
    "path_poses = f\"/home/sergio/onboarding_stage/data/{dataset}/obj_{object_id:06d}/align/sparse/0/images.txt\"\n",
    "poses = read_pose_matrices(path_poses)\n",
    "poses_mat = [poses[idx]['pose'] for idx in range(len(poses))]\n",
    "t_vecs = [pose_mat[:3, 3] for pose_mat in poses_mat]\n",
    "t_vecs = np.vstack(t_vecs)\n",
    "\n",
    "# pcd align up\n",
    "pcd_cams_up = o3d.geometry.PointCloud()\n",
    "pcd_cams_up.points = o3d.utility.Vector3dVector(t_vecs[:7])\n",
    "pcd_cams_up.colors = o3d.utility.Vector3dVector(np.array([0, 255, 0] * 7).reshape(7, -1))\n",
    "# pcd align down \n",
    "pcd_cams_down = o3d.geometry.PointCloud()\n",
    "pcd_cams_down.points = o3d.utility.Vector3dVector(t_vecs[7:])\n",
    "pcd_cams_down.colors = o3d.utility.Vector3dVector(np.array([0, 0, 255] * 7).reshape(7, -1))\n",
    "\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_aux, pcd_cams_up, pcd_cams_down])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### color icp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colored point cloud registration\n",
      "[1500, 2, 0]\n",
      "Downsample with a voxel size 2.00\n",
      "Estimate normal.\n",
      "Applying colored point cloud registration\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=3.104685e-03, and correspondence_set size of 87687\n",
      "Access transformation to get result.\n",
      "[1000, 1, 1]\n",
      "Downsample with a voxel size 1.00\n",
      "Estimate normal.\n",
      "Applying colored point cloud registration\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=3.104694e-03, and correspondence_set size of 87687\n",
      "Access transformation to get result.\n",
      "[250, 0.5, 2]\n",
      "Downsample with a voxel size 0.50\n",
      "Estimate normal.\n",
      "Applying colored point cloud registration\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=3.105831e-03, and correspondence_set size of 87687\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "def align_point_clouds(source_path, target_path, mode, threshold=0.02):\n",
    "    # Load source and target point clouds\n",
    "    source = o3d.io.read_point_cloud(source_path)\n",
    "    target = o3d.io.read_point_cloud(target_path)\n",
    "\n",
    "    # flip 180 degrees \n",
    "    R = np.array([[1,  0,  0],\n",
    "                  [0, -1,  0],\n",
    "                  [0,  0, -1]])\n",
    "    centroid_src = source.get_center()\n",
    "    source.translate(-centroid_src)\n",
    "    source.rotate(R, center=(0, 0, 0))\n",
    "    source.translate(centroid_src)\n",
    "    # align centroids \n",
    "    centroid_trg = target.get_center()\n",
    "    diff_centers = centroid_trg - centroid_src\n",
    "    source.translate(diff_centers)\n",
    "\n",
    "    if mode == \"simple\":\n",
    "        result_icp = simple_icp(source, target, threshold)\n",
    "    elif mode == \"color\":\n",
    "        result_icp = multi_scale_color_icp(source, target)\n",
    "    elif mode == \"features\":\n",
    "        result_icp = multi_scale_color_icp_with_fpfh(source, target)\n",
    "    else:\n",
    "        return print(\"no aligning method recognized\")\n",
    "\n",
    "    # Transform source point cloud\n",
    "    source.transform(result_icp.transformation)\n",
    "\n",
    "    return source, target, result_icp.transformation, centroid_src, centroid_trg\n",
    "\n",
    "def multi_scale_color_icp(source, target):\n",
    "    voxel_radius = [2, 1, 0.5]\n",
    "    max_iter = [1500, 1000, 250]\n",
    "    current_transformation = np.identity(4)\n",
    "    print(\"Colored point cloud registration\")\n",
    "    for scale in range(3):\n",
    "        iter = max_iter[scale]\n",
    "        radius = voxel_radius[scale]\n",
    "        print([iter, radius, scale])\n",
    "\n",
    "        print(\"Downsample with a voxel size %.2f\" % radius)\n",
    "        # source_down = source.voxel_down_sample(radius)\n",
    "        # target_down = target.voxel_down_sample(radius)\n",
    "        source_down = source\n",
    "        target_down = target\n",
    "\n",
    "        print(\"Estimate normal.\")\n",
    "        source_down.estimate_normals(\n",
    "            o3d.geometry.KDTreeSearchParamHybrid(radius=radius * 2, max_nn=30))\n",
    "        target_down.estimate_normals(\n",
    "            o3d.geometry.KDTreeSearchParamHybrid(radius=radius * 2, max_nn=30))\n",
    "\n",
    "        print(\"Applying colored point cloud registration\")\n",
    "        result_icp = o3d.pipelines.registration.registration_colored_icp(\n",
    "            source_down, target_down, radius, current_transformation,\n",
    "            o3d.pipelines.registration.TransformationEstimationForColoredICP(),\n",
    "            o3d.pipelines.registration.ICPConvergenceCriteria(relative_fitness=1e-7,\n",
    "                                                            relative_rmse=1e-7,\n",
    "                                                            max_iteration=iter))\n",
    "        current_transformation = result_icp.transformation\n",
    "        print(result_icp)\n",
    "\n",
    "    return  result_icp\n",
    "\n",
    "def simple_icp(source, target, threshold):\n",
    "    # Perform ICP registration\n",
    "    initial_transform = np.eye(4)\n",
    "    result_icp = o3d.pipelines.registration.registration_icp(\n",
    "        source,\n",
    "        target,\n",
    "        threshold,\n",
    "        initial_transform,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "    )\n",
    "    print(result_icp)\n",
    "    return result_icp\n",
    "\n",
    "def concatenate_point_clouds(source, target):\n",
    "    # Load vertices and colors from source and target\n",
    "    source_xyz = np.asarray(source.points)\n",
    "    target_xyz = np.asarray(target.points)\n",
    "\n",
    "    source_rgb = np.asarray(source.colors) * 255  # Convert to 0-255 scale\n",
    "    target_rgb = np.asarray(target.colors) * 255\n",
    "\n",
    "    source_normals = np.asarray(source.normals) if source.has_normals() else np.zeros_like(source_xyz)\n",
    "    target_normals = np.asarray(target.normals) if target.has_normals() else np.zeros_like(target_xyz)\n",
    "\n",
    "    # Concatenate points, colors, and normals\n",
    "    combined_xyz = np.vstack((source_xyz, target_xyz))\n",
    "    combined_rgb = np.vstack((source_rgb, target_rgb)).astype(np.uint8)\n",
    "    combined_normals = np.vstack((source_normals, target_normals))\n",
    "\n",
    "    return combined_xyz, combined_rgb, combined_normals\n",
    "\n",
    "def save_combined_point_cloud(combined_xyz, combined_rgb, combined_normals, output_path):\n",
    "    dtype = [('x', 'f4'), ('y', 'f4'), ('z', 'f4'),\n",
    "             ('nx', 'f4'), ('ny', 'f4'), ('nz', 'f4'),\n",
    "             ('red', 'u1'), ('green', 'u1'), ('blue', 'u1')]\n",
    "\n",
    "    elements = np.empty(combined_xyz.shape[0], dtype=dtype)\n",
    "    attributes = np.concatenate((combined_xyz, combined_normals, combined_rgb), axis=1)\n",
    "    elements[:] = list(map(tuple, attributes))\n",
    "\n",
    "    vertex_element = PlyElement.describe(elements, 'vertex')\n",
    "    ply_data = PlyData([vertex_element])\n",
    "    ply_data.write(output_path)\n",
    "\n",
    "###################################################\n",
    "\n",
    "def multi_scale_color_icp_with_fpfh(source, target):\n",
    "    \"\"\"\n",
    "    Perform multi-scale color ICP with feature-based matching using FPFH features.\n",
    "\n",
    "    Parameters:\n",
    "        source: open3d.geometry.PointCloud - Source point cloud\n",
    "        target: open3d.geometry.PointCloud - Target point cloud\n",
    "\n",
    "    Returns:\n",
    "        result_icp: RegistrationResult - The final registration result\n",
    "    \"\"\"\n",
    "    voxel_radius = [1.5, 1, 0.8]\n",
    "    max_iter = [600, 200, 100]\n",
    "    current_transformation = np.identity(4)\n",
    "    \n",
    "    print(\"Extracting FPFH features...\")\n",
    "    source_fpfh = compute_fpfh_features(source, voxel_radius[0])\n",
    "    target_fpfh = compute_fpfh_features(target, voxel_radius[0])\n",
    "\n",
    "    print(\"Performing feature-based global registration...\")\n",
    "    distance_threshold = voxel_radius[0] * 1.5\n",
    "    global_registration = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source, target, source_fpfh, target_fpfh, False, distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "        4,  # Number of RANSAC iterations\n",
    "        [o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "         o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)],\n",
    "        o3d.pipelines.registration.RANSACConvergenceCriteria(4000000, 500)\n",
    "    )\n",
    "\n",
    "    current_transformation = global_registration.transformation\n",
    "    # print(\"Initial transformation from global registration:\")\n",
    "    # print(current_transformation)\n",
    "\n",
    "    print(\"Performing multi-scale colored ICP...\")\n",
    "    for scale in range(len(voxel_radius)):\n",
    "        iter = max_iter[scale]\n",
    "        radius = voxel_radius[scale]\n",
    "        print(f\"Scale {scale}: voxel size = {radius}, max iterations = {iter}\")\n",
    "        \n",
    "        print(\"Downsampling point clouds...\")\n",
    "        source_down = source.voxel_down_sample(radius)\n",
    "        target_down = target.voxel_down_sample(radius)\n",
    "\n",
    "        print(\"Estimating normals...\")\n",
    "        source_down.estimate_normals(\n",
    "            o3d.geometry.KDTreeSearchParamHybrid(radius=radius * 2, max_nn=30))\n",
    "        target_down.estimate_normals(\n",
    "            o3d.geometry.KDTreeSearchParamHybrid(radius=radius * 2, max_nn=30))\n",
    "\n",
    "        print(\"Refining registration with colored ICP...\")\n",
    "        result_icp = o3d.pipelines.registration.registration_colored_icp(\n",
    "            source_down, target_down, radius, current_transformation,\n",
    "            o3d.pipelines.registration.TransformationEstimationForColoredICP(),\n",
    "            o3d.pipelines.registration.ICPConvergenceCriteria(relative_fitness=1e-6,\n",
    "                                                                relative_rmse=1e-6,\n",
    "                                                                max_iteration=iter))\n",
    "        current_transformation = result_icp.transformation\n",
    "\n",
    "    # print(\"Final transformation:\")\n",
    "    # print(current_transformation)\n",
    "    return result_icp\n",
    "\n",
    "def compute_fpfh_features(point_cloud, voxel_size):\n",
    "    \"\"\"\n",
    "    Compute FPFH features for a point cloud.\n",
    "    \n",
    "    Parameters:\n",
    "        point_cloud: open3d.geometry.PointCloud - The input point cloud\n",
    "        voxel_size: float - The voxel size for downsampling and feature extraction\n",
    "    \n",
    "    Returns:\n",
    "        fpfh: open3d.pipelines.registration.Feature - The computed FPFH features\n",
    "    \"\"\"\n",
    "    print(\"Downsampling for FPFH computation...\")\n",
    "    pcd_down = point_cloud.voxel_down_sample(voxel_size)\n",
    "\n",
    "    print(\"Estimating normals...\")\n",
    "    pcd_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(\n",
    "        radius=voxel_size * 2, max_nn=30))\n",
    "\n",
    "    print(\"Computing FPFH features...\")\n",
    "    fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 5, max_nn=100))\n",
    "    return fpfh\n",
    "\n",
    "source_path = \"/home/sergio/onboarding_stage/data/hope/obj_000001/down/20_views/sparse/0/points3D.ply\"\n",
    "target_path = \"/home/sergio/onboarding_stage/data/hope/obj_000001/up/20_views/sparse/0/points3D.ply\"\n",
    "\n",
    "source, target, transformation, centroid_source, centroid_target = align_point_clouds(\n",
    "    source_path,\n",
    "    target_path, mode=\"color\" \n",
    ")\n",
    "\n",
    "# Concatenate point clouds\n",
    "combined_xyz, combined_rgb, combined_normals = concatenate_point_clouds(source, target)\n",
    "save_combined_point_cloud(combined_xyz, combined_rgb, combined_normals, \"./points3D.ply\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gs_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
